<!DOCTYPE HTML>
<html lang="en">

<head>
  <title>{{ site.name }}</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="{{ site.name }}" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="{{ site.baseurl }}/style.css" />
  <link rel="canonical" href="{{ page.url | replace:'index.html','' | prepend: site.baseurl | prepend: site.url }}">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
  
</head>

  
<style>
.listbox{
    position: static;
    overflow-y: scroll;
    height: 300px;
    color: black;
    background-color: #EAF4F7;
/*     border: 2px solid black; */
/*     padding: 20px 50px 0px 30px; */
/*     font-size: 15px; */
    }
</style>

<style>
  .navA{
    display: inline-block;
    margin-right: 13px;
    font-size: 16px;
    font-weight: 700;
    color: #000;
    text-decoration: none;
    padding: 5px ;
    border: #000 1px solid;
  }
  .navA:hover{
    color: #fff;
    background-color: #000;
  }
</style>
  
<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <h1>
                Zhen Wang / 王震
              </h1>
              <p>
                Hi! I'm Zhen, currently a postdoctoral researcher at UC San Diego, working with Prof. <a href="https://zhiting.ucsd.edu/">Zhiting Hu</a> and Prof. <a href="https://mbzuai.ac.ae/study/faculty/professor-eric-xing/">Eric P. Xing</a>, focusing on advancing foundation agentic systems and scientific discovery. I obtained my PhD from The Ohio State University, advised by Prof. <a href="https://cse.osu.edu/people/sun.397">Huan Sun</a>, where I developed foundational frameworks for knowledge-centric NLP systems.
              </p>
              <p>
                I'm fortunate to have the privilege of working with exceptional researchers like <a href="https://rpand002.github.io/">Rameswar Panda</a>, <a href="https://people.csail.mit.edu/yoonkim/">Yoon Kim</a>, <a href="https://scholar.google.com/citations?user=iS5UrMkAAAAJ&hl=en">Nebojsa Jojic</a>, <a href="https://malkin1729.github.io/">Nikolay Malkin</a>, <a href="https://scholar.google.com/citations?user=WbO7tjYAAAAJ&hl=en">Leonid Karlinsky</a>, and <a href="https://bzong.github.io/">Bo Zong</a> across premier industrial labs (<a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Lab</a>, <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-redmond/">Microsoft Research</a>, <a href="https://www.nec-labs.com/">NEC Labs America</a>) and academic institutions (UCSD, CMU, MBZUAI). I've been honored with the OpenAI Agentic AI Research Grant, SoCal NLP 2023 Best Paper Award, Alexa Prize TaskBot Challenge 2022, and Rising Star in Data Science 2021.
<!--                 These partnerships have advanced research frontiers in foundation models, efficient adaptation, and reliable AI systems. -->
              </p>
              <p>
                Outside of research, you'll find me exploring hiking trails, playing pickleball, or planning my next adventure in national parks. I'm also a passionate sports fan, cheering for the <a style="color:#BB0000;">Buckeyes</a>, <a style="color:#005596;">Dodgers</a>, <a style="color:#FDB927;">Lakers</a>, <a style="color:#F7B5CD;">Inter Miami</a>, and <a style="color:#E31837;">Chiefs</a> (for reasons unrelated to tight ends).
              </p>

              <p style="text-align:center">
                <a href="mailto:zhenwang9102@gmail.com">Email</a> &nbsp;/&nbsp;
                <a href="https://github.com/zhenwang9102">GitHub</a> &nbsp;/&nbsp;
                <a href="https://twitter.com/zhenwang9102">Twitter</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?hl=en&user=asBaytUAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a> 
<!--                 &nbsp;/&nbsp; -->
<!--                 <a href="https://www.linkedin.com/in/zhenwang9102/">LinkedIn </a>  -->
<!--                 &nbsp;/&nbsp; -->
<!--                 <a href="https://www.semanticscholar.org/author/Zhen-Wang/47197370">Semantic Scholar</a> -->
              </p>
              
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/IMG_0023_S.png">
              <figcaption><em>At a rooftop in Anchorage, Alaska 2019</em></figcaption>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              
              <h2>Research Overview</h2>
              <p>
                <b>Building <a style="background-color:#d9ead3;color:black;">Trustworthy</a> Systems that <a style="background-color:#fff2cc;color:black;">Perceive</a>, <a style="background-color:#f5cbcc;color:black;">Think</a>, and <a style="background-color:#c9daf8;color:black;">Act</a></b>: Today's most advanced AI systems, despite their impressive capabilities, remain fundamentally reactive — unable to actively explore possibilities, strategically plan actions, or safely adapt their behavior in the real world. This limitation becomes increasingly critical as AI systems are deployed in scenarios requiring sustained interaction, complex reasoning, and reliable real-world engagement.
              </p>
              <p>
                My research establishes <b>Foundation Agentic Systems</b> that transform how AI engages with complex worlds across <b>the perception-cognition-action loop while ensuring reliable governance</b>.
              </p>
              <ul>
                <li>
                  <a style="background-color:#fff2cc;">&nbsp;&nbsp;&nbsp;</a> <b>World Model-based Simulation and Planning</b>: At its core, active intelligence requires the ability to simulate and reason about potential futures. My research introduces principled world model formulation, enabling AI systems for active simulation and strategic planning. [<a href="https://github.com/maitrix-org/llm-reasoners">LLM-reasoners</a>, COLM'24; <a href="https://arxiv.org/abs/2310.16427">PromptAgent</a> , ICLR'24]                  
                </li>
                <li>
                  <a style="background-color:#f5cbcc;">&nbsp;&nbsp;&nbsp;</a> <b>Structured Reasoning and Inference-compute Scaling</b>: Structure, whether explicit in graphs or implicit in language spaces, provides the key to achieve reliable and interpretable reasoning. [<a href="https://arxiv.org/abs/2305.14992">RAP</a>, EMNLP'23; <a href="https://arxiv.org/abs/2210.01293">ThinkSum</a>, ACL'23; <a href="https://arxiv.org/abs/1906.09285">SurfCon</a>, KDD'19]
                </li>
                <li>
                  <a style="background-color:#c9daf8;">&nbsp;&nbsp;&nbsp;</a> <b>Efficient Adaptation and Real-world Interaction</b>: Real-world deployment demands extreme computational efficiency in behavioral adaptation and real-world interaction. My research achieves this through minimal-overhead architectures and parameter-efficient techniques. [<a href="https://arxiv.org/abs/2305.11554">ToolkenGPT</a>, NeurIPS'23 Oral; <a href="https://arxiv.org/abs/2303.02861">MPT</a>, ICLR'23].
                </li>
                <li>
                  <a style="background-color:#d9ead3;">&nbsp;&nbsp;&nbsp;</a> <b>Scalable Methods for Safety, Alignment, and Oversight</b>: Governance must scale with AI capabilities without unsustainable scaling of computational or human resources. Our approaches pioneer algorithmic solutions that grow more effective as systems become more capable. [<a href="https://arxiv.org/abs/2411.08733">DRPO</a>,EMNLP2'24; <a href="https://de-arena.maitrix.org/">Decentralized Arena</a>]
                  
                </li>
              </ul>
              
              <p>
                <a style="color:red"><b>Research Opportunities</b></a>: I consistently seek out highly motivated students, particularly from underrepresented groups, to join me in various research projects both during the school year and throughout the summer. If you are interested in LLM augmentation (reasoning, tool-using, planning, etc), LLM agents, and AI4Science research, kindly email me expressing your interest.
              </p>
              
            </td>
          </tr>
        </table>

        <div class="navbar" style="padding-left: 18px;">
          <a href="/index.html" class="navA">About</a>
          <a href="/page_pubs.html" class="navA">Publications</a>
          <a href="/page_posts.html" class="navA">Blogs</a>
          <a href="/page_honors_and_services.html" class="navA">Honors and Services</a>
        </div>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>News</h2>
              <p></p>
              <div class="listbox">
                 <ul>
                 <li>
                   10/2024: Excited to release <a href="https://de-arena.maitrix.org/" style="color:red">Decentralized Arena</a>, a decentralized and democratic LLM benchmarking system, where all LLMs participating in judging each other. It's an automated, fully transparent, faster, more scalable, and less biased version of Chatbot Arena. Check our <a href="https://huggingface.co/spaces/LLM360/de-arena">HF leaderboard</a>.
                 </li>
                 <li>
                   10/2024: Happy to help release the <a href="https://huggingface.co/spaces/LLM360/TxT360" style="color:red">TxT360: A Top-Quality LLM Pre-training Dataset Requires the Perfect Blend</a>. It is the first dataset to globally deduplicate 99 CommonCrawl snapshots and 14 high-quality data sources. Download the dataset for your LLM pre-training <a href="https://huggingface.co/datasets/LLM360/TxT360">here</a>.
                 </li>
                 <li>
                   09/2024: <a style="color:red">DRPO (Dynamic Rewarding with Prompt Optimization)</a> was accepted to the main conference of <a href="https://2024.emnlp.org/">EMNLP 2024</a>. It is the first tuning-free method to self-align LLMs with human preferences, without any model tuning or human preference annotations.
                 </li>
                 <li>
                   07/2024: Excited to be selected to attend <a href="https://datascience.uchicago.edu/events/ai-science-summer-school-2024/">2024 AI+Science Summer School at the University of Chicago</a>!
                 </li>
                 <li>
                   07/2024:  <a href="https://arxiv.org/abs/2404.05221">LLM Reasoners</a> has been accepted to <a href="https://colmweb.org/">COLM 2024</a>. Congrats to the LLM Reasoners team. Check out our brilliant +1k stars <a href="https://github.com/maitrix-org/llm-reasoners">GitHub package</a> for advanced reasoning with LLMs!
                 </li>
                 <li>
                    02/2024: Received a research grant from OpenAI to support our research in agentic systems!
                  </li>
                  <li>
                    01/2024: Wrote a blog, <a href="https://zhenwang.notion.site/Reflecting-on-ChatGPT-s-First-Year-Evolutions-Twists-and-Smooth-Directions-2381d752b5c94012bd21269f46d12a08?pvs=4" style="color:red">Reflecting on ChatGPT’s First Year: Evolutions, Twists, and Smooth Directions</a>, discussing recent NLP research directions heavily impacted by ChatGPT-related techniques. Welcome to any comments! 
                  </li>
                  <li>
                    01/2024: Invited to serve as a Reviewer for <a href="https://kdd2024.kdd.org/">KDD 2024</a>, <a href="https://icml.cc/Conferences/2024">ICML 2024</a>, and <a href="https://colmweb.org/">COLM 2024</a> (The first conference on language modeling! Happy to contribute to making this a success!)
                  </li>
                  <li>
                    01/2024: <a href="https://arxiv.org/abs/2310.16427" style="color:red">PromptAgent</a> was accepted to <a href="https://iclr.cc/Conferences/2024">ICLR 2024</a>! The first principled framework to formalize the problem of API-based discrete prompt optimization and benchmark the exploration efficiency and prompt transferability!
                  </li>
                  <li>
                    12/2024: Attended <a href="https://nips.cc/Conferences/2023">NeurIPS 2023</a> at NOLA! Happy to meet many old and new friends! 
                  </li>
                  <li>
                    11/2023: Honored to receive the <a href="https://neurips.cc/Conferences/2023/ProgramCommittee#top-reivewers"><b>Top Reviewer Award</b></a> of NeurIPS 2023. Thanks for the complimentary registration!
                  </li>
                  <li>
                    11/2023: Honored to receive the <a style="color:red"><b>Best Paper Award</b></a> at <a href="https://socalnlp.github.io/symp23/index.html">SoCal NLP 2023</a>.
                  </li>
                  <li>
                    11/2023: Three papers, <a href="https://arxiv.org/abs/2305.14992">RAP</a>, <a href="https://arxiv.org/abs/2305.11554">ToolkenGPT</a>, and <a href="https://arxiv.org/abs/2310.16427">PromptAgent</a>, will be presented at <a href="https://socalnlp.github.io/symp23/index.html">SoCal NLP 2023</a> at UCLA on Nov. 17th, 2023.
                  </li>
                  <li>
                    10/2023: <a href="https://arxiv.org/abs/2305.14992">Reasoning via Planning</a> has been featured in the recently published <a href="https://www.stateof.ai/2023-report-launch" style="color:red">State of AI Report 2023</a>. Check the great report <a href="https://docs.google.com/presentation/d/156WpBF_rGvf4Ecg19oM1fyR51g4FAmHV3Zs0WLukrLQ/edit#slide=id.g24daeb7f4f0_0_3930" style="color:red">here</a>!
                  </li>
                  <li>
                    10/2023: <a href="https://arxiv.org/abs/2305.14992" style="color:red">Reasoning via Planning</a> paper that augments LLM reasoning with external world models and principled planning was accepted to <a href="https://2023.emnlp.org/">the main conference of EMNLP 2023</a>!
                  </li>
                  <li>
                    09/2023: <a href="https://arxiv.org/abs/2210.01293" style="color:red">ToolkenGPT</a> paper that augments LLMs with efficient and plug-and-play tool learning was accepted as <a href="https://nips.cc/Conferences/2023">an oral presentation of NeurIPS 2023</a>!
                  </li>
                  <li>
                    08/2023: Invited to serve as a Reviewer for <a href="https://iclr.cc/Conferences/2024">ICLR 2024</a>.
                  </li>
                  <li>
                    07/2023: Invited to serve as a PC member for <a href="https://aaai.org/aaai-conference/">AAAI 2024</a>.
                  </li>
                  <li>
                    06/2023: Invited to give a talk at <b>George Mason University</b> on June 13th, 2023.
                  </li>
                  <li>
                    06/2023: Invited to give a talk at <b>North Carolina State University</b> on June 3rd, 2023.
                  </li>
                  <li>
                    06/2023: Invited to serve as a Reviewer for <a href="https://2023.emnlp.org/">EMNLP 2023</a>.
                  </li>
                  <li>
                    05/2023: One paper about <a href="https://arxiv.org/abs/2210.01293" style="color:red">prompting LLMs with probabilistic reasoning</a> was accepted to <a href="https://2023.aclweb.org/">ACL 2023</a>!
                  </li>
                  <li>
                    03/2023: Invited to serve as a Reviewer for <a href="https://nips.cc/Conferences/2023">NeurIPS 2023</a>.
                  </li>
                  <li>
                    03/2023: Invited to serve as an Area Chair for <a href="http://tcci.ccf.org.cn/conference/2023/index.php">NLPCC 2023</a>.
                  </li>
                  <li>
                    02/2023: Kicked off my postdoc adventure! 😎 Super stoked to work with the brilliant minds from UCSD, CMU, MBZUAI, and beyond to  push the boundaries of those incredible large language models and harness their power for human society and other scientific domains! 🚀🔬💡
                  </li>
                  <li>
                    01/2023: One paper, <a href="https://arxiv.org/abs/2303.02861" style="color:red">Multitask Prompt Tuning</a>, was accepted to <a href="https://iclr.cc/">ICLR 2023</a>!
                  </li>
                  <li>
                    01/2023: One paper, <a href="https://arxiv.org/abs/2210.06444" style="color:red">Entity Tracking via Effective Use of Multi-Task Learning Models</a>, was accepted to <a href="https://2023.eacl.org/">EACL 2023</a>!
                  </li>
                  <li>
                    01/2023: Invited to serve as a Reviewer for <a href="https://icml.cc/Conferences/2023">ICML 2023</a>.
                  </li>
                  <li>
                    12/2022: Invited to serve as a PC Member for <a href="https://kdd.org/kdd2023/">KDD 2023</a> Research Track.
                  </li>
                  <li>
                    12/2022: Happy to finish my first in-person NLP course teaching, and I'm impressed by what students have achieved after learning the very advanced NLP techniques. Check out <a href="https://docs.google.com/presentation/d/1TA_Gf29CbGe0UV5NR_uPnaGr7dP7-ipNuz-BtNne3_0/edit?usp=sharing">this quick summary of their amazing final projects</a>!
                  </li>
                  <li>
                    11/2022: Passed the Ph.D. dissertation defense, <a>Toward Knowledge-centric Natural Language Processing: Acquisition, Representation, Transfer, and Reasoning</a>. Thanks to all my committee members, Prof. Huan Sun, Srinivasan Parthasarathy, Yu Su, and Wei-Lun Chao. 
                  </li>
                  <li>
                    08/2022: Will be teaching <a>CSE 5525: Foundations of Speech and Language Processing (Undergrad & Graduate)</a> as an instructor at OSU this fall.
                  </li>
                  <li>
                    08/2022: Invited to serve as a PC member for <a href="https://aaai.org/Conferences/AAAI-23//">AAAI 2023</a>.
                  </li>
                  <li>
                    07/2022: Attended NAACL 2022 in Seattle. Presented <a href="https://aclanthology.org/2022.suki-1.7.pdf">our CQA Knowledge Transfer paper</a>. Glad to meet all my old and new friends! 
                  </li>
                  <li>
                    06/2022: Invited to serve as a PC member for <a href="https://2022.emnlp.org/">EMNLP 2022</a>.
                  </li>
                  <li>
                    06/2022: Happy to give a talk about <a>Efficient Adaptation of Large Language Models</a> at the <a>MIT Summer Working Group on Large LMs</a>.
                  </li>
                  <li>
                    06/2022: Our TacoBot earned the <a href="https://www.amazon.science/alexa-prize/three-top-performers-emerge-in-inaugural-alexa-prize-taskbot-challenge" style="color:red">third-place honor in the inaugural Alexa Prize TaskBot Challenge</a>!
                  </li>
                  <li>
                    06/2022: Happy to give a tutorial about natural language processing and large language models in <a href="https://tdai.osu.edu/events/tdai-foundations-cop-deep-learning-summer-school">TDAI Deep Learning Summer School</a> along with Prof. Huan Sun. Slides can be found <a href="https://tdai.osu.edu/sites/default/files/2022-06/2022-foundations-tutorial3-sunwang-deeplearning4nlp.pdf">here</a>.
                  </li>
                  <li>
                    05/2022: Excited to join <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a> in Cambridge, Boston as a research intern working with <a href="https://rpand002.github.io/">Rameswar Panda</a> and <a href="https://people.csail.mit.edu/yoonkim/">Yoon Kim</a> on efficient adaptation/pruning for large language models.
                  </li>
                  <li>
                    03/2022: Our team TacoBot moved forward to finals of the <a href="https://www.amazon.science/alexa-prize/taskbot-challenge">Alexa Prize TaskBot challenge</a>!
                  </li>
                  <li>
                    03/2022: Honored to receive the <a>2022 Graduate Research Award</a> of the CSE department. 
                  </li>
                  <li>
                    02/2022: One paper, <a href="https://arxiv.org/abs/2110.08294">Coherence boosting: When your pretrained language model is not paying enough attention</a>, was accepted to <a href="https://www.2022.aclweb.org/">ACL 2022</a>!
                  </li>
                  <li>
                    02/2022: Our team TacoBot moved forward to the semifinals of the <a href="https://www.amazon.science/alexa-prize/taskbot-challenge">Alexa Prize TaskBot challenge</a>! Try "<a href="https://www.amazon.science/blog/alexa-assist-me-is-now-live">Alexa, let's work together</a>" or "Alexa, assist me" in your Alexa devices or the app when you want to do a DIY or cooking task!
                  </li>
                  <li>
                    12/2021: Passed the Ph.D. candidacy exam with the proposal, "<a href="https://zhenwang9102.github.io/files/candidacy_abstract.txt">Knowledge-centric Natural Language Processing: Acquisition, Representation, and Reasoning</a>." Thanks to all my committee members, Prof. Huan Sun, Srinivasan Parthasarathy, Yu Su, and Wei-Lun Chao. 
                  </li>
                  <li>
                    05/2021: Our team was selected to participate in the <a href="https://www.amazon.science/alexa-prize/taskbot-challenge/2021">Alexa Prize TaskBot Challenge</a> as one of 10 teams over 125 applications initiated from 15 countries! Looking forward to building a smart dialogue system to guide users through complex, multi-step plans (e.g., Cooking and DIY tasks) via multimodal interactions.
                  </li>
                  <li>
                    05/2021: Started Research Intern at Microsoft Research! Excited to work with <a href="https://www.microsoft.com/en-us/research/people/jojic/">Nebojsa Jojic</a> and <a>Kolya Malkin</a> on Conditional Text Generation!
                  </li>
                  <li>
                    03/2021: Invited to serve as a PC member of EMNLP 2021.
                  </li>
                  <li>
                    03/2021: Attended WSDM 2021 virtually and presented our work on <a href="https://dl.acm.org/doi/10.1145/3437963.3441744">modeling context pair interaction and learning graph pair emebddings</a>.
                  </li>
                  <li>
                    03/2021: Honored to win <a>Graduate Student Research Poster Award (Top 5)</a> for the 2021 Annual Student Research Poster Exhibition in our CSE department.
                  </li>
                  <li>
                    02/2021: Panelist on the panel discussion in Department of Astronomy, "<a href="https://astronomy.osu.edu/events/monthly-movie-night-2001-space-odyssey-science-fiction-vs-science-fact">2001: A Space Odyssey - Science Fiction vs. Science Fact</a>", discussing Science Fiction, Life in Universe, Time & Relativity and Anthropology.
                  </li>
                  <li>
                    01/2021: Received SIGIR Student Travel Grant for WSDM 2021.
                  </li>
                  <li>
                    01/2021: Attended CDAC Rising Stars in Data Science Workshop with the agenda <a href="https://cdac.uchicago.edu/events/risingstars2021">here</a>.
                  </li>
                  <li>
                    12/2020: Honored to be selected to the <a href="https://datascience.uchicago.edu/rising-stars-alumni/" style="color:red">Rising Stars in Data Science</a> workshop hosted by the <a href="https://cdac.uchicago.edu/">Center for Data and Computing (CDAC) at the University of Chicago</a>.
                  </li>
                  <li> 
                    12/2020: Invited to serve as a PC member of ACL 2021.
                  </li>
                  <li> 
                    10/2020: Invited to serve as a PC member of NAACL 2021.
                  </li>
                  <li>
                    10/2020: One paper, <a href="https://zhenwang9102.github.io/files/WSDM2021_ZW_ConPI.pdf">Modeling Context Pair Interaction for Pairwise Tasks on Graphs</a>, was accepted to WSDM 2021 (<a style="color:red">Acceptance Rate: 18.6%</a>).
                  </li>
                  <li>
                    07/2020: Attended ACL 2020 virtually and presented our paper via QA sessions and pre-recorded video.
                  </li>
                  <li>
                    05/2020: Started Research Intern at <a href="http://www.nec-labs.com/">NEC Labs America</a>! Excited to work with <a href="https://bzong.github.io/">Dr. Bo Zong</a> on Commonsense Reasoning for NLU.
                  </li>
                  <li>
                    04/2020: One paper, <a href="https://zhenwang9102.github.io/files/ACL2020_ZW_X_MedRELA.pdf">Rationalizing Medical Relation Prediction from Corpus-level Statistics</a>, about building self-interpretable deep learning model for relation prediction was accepted by <a href="https://acl2020.org/"></a>ACL 2020 (<a style="color:red">Acceptance Rate: 22.7%</a>).
                  </li>
                  <li>
                    04/2020: Invited to serve as a PC member of NLPCC 2020.
                  </li>
                  <li>
                    09/2019: One paper, <a href="https://academic.oup.com/bioinformatics/article/36/4/1241/5581350">Graph Embedding on Biomedical Networks: Methods, Applications, and Evaluations</a>, was accepted by <a href="https://academic.oup.com/bioinformatics">Bioinformatics</a>.
                  </li>
                  <li>
                    08/2019: Attended KDD 2019 in Anchorage, Alaska, and presented our work in an oral talk.
                  </li>
                  <li>
                    06/2019: Received SIGKDD Student Travel Award for KDD 2019.
                  </li>
                  <li>
                    04/2019: One paper, <a href="https://zhenwang9102.github.io/files/KDD2019_ZW_SurfCon_paper.pdf">SurfCon: Synonym Discovery on Privacy-Aware Clinical Data</a>, about knowledge extraction from text was accepted by <a href="https://www.kdd.org/kdd2019/">KDD 2019</a> (Research Track, <a style="color:red">Acceptance Rate: 14.2%</a>, Oral).
                  </li>
                  <li>
                    08/2018: One paper about <a href="https://ziyuyao.org/paper/StaQC_DLDay18.pdf">Code Summarization</a> was accepted by KDD 2018, Deep Learning Day.
                  </li>
                  <li>
                    06/2018: Attended NAACL 2018 in New Orleans, LA.
                  </li>
                </ul>
              </div>
            </td>
          </tr>
        </table>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Research Highlights</h2>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/dearena.png" alt="dearena" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://de-arena.maitrix.org/" style="color:red">Decentralized Arena: When LLMs Replace Human Judges for Democratic and Scalable LLM Leaderboard</a></h3>
              <br>
              <br>
              <a href="https://de-arena.maitrix.org/">Blog</a> / <a href="https://huggingface.co/spaces/LLM360/de-arena">Leaderboard</a>
              <p>Decentralized Arena introduces an automated, scalable system for evaluating LLMs across specialized domains, where the models themselves participate in assessing each other. This democratic evaluation approach achieves 95% correlation with Chatbot Arena rankings while maintaining full transparency and reproducibility.</p>
            </td>
          </tr>
        </table>

        
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="width:100%;vertical-align:middle;">
              <h3><a href="https://arxiv.org/abs/2310.16427" style="color:red">PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization</a></h3>
              <em><b>[ICLR 2024]</b></em> <i>The Twelfth International Conference on Learning Representations</i> 
              <br>
              <a href="https://arxiv.org/pdf/2310.16427.pdf">PDF</a> / <a href="https://github.com/XinyuanWangCS/PromptAgent">Code</a> / <a href="http://zhenwang9102.github.io/">Slides</a> / <a href="https://zhenwang9102.github.io/files/promptagnet_poster_2023.pdf">Poster</a>
              <p>Tired of manual prompt engineering? PromptAgent offers the first principled framework to formalize the problem of API-based prompt optimization (state, action, reward, etc); also the first to benchmark exploration efficiency and show the transferability of optimized prompts. Targeting for expert-level prompting, there are many exciting directions ahead of PromptAgent!</p>
            </td>
          </tr>
        </table>
        
                
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="width:100%;vertical-align:middle;">
              <h3><a href="https://arxiv.org/abs/2305.14992">Reasoning with Language Model is Planning with World Model</a></h3>
              <em><b>[EMNLP 2023] (Oral, Main)</b></em> <i>The 2023 Conference on Empirical Methods in Natural Language Processing</i>
              <br>
              <a href="https://arxiv.org/pdf/2305.14992.pdf">PDF</a> / <a href="https://github.com/Ber666/llm-reasoners">Code</a> / <a href="http://zhenwang9102.github.io/">Slides</a> / <a href="http://zhenwang9102.github.io/">Poster</a> / <a href="https://docs.google.com/presentation/d/156WpBF_rGvf4Ecg19oM1fyR51g4FAmHV3Zs0WLukrLQ/edit#slide=id.g24daeb7f4f0_0_3930" style="color:red"><b>Featured in State of AI Report 2023</b></a>
              <p>LLMs lack internal world models for effective reasoning. Reasoning via Planning (RAP) reformulates LLM reasoning as a planning problem, thus incorporating an external world model and principled planning seamlessly. This is a new framework applicable across varying tasks and an exciting direction for LLM augmentation research.</p>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="width:100%;vertical-align:middle;">
              <h3><a href="https://arxiv.org/abs/2305.11554">ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings</a></h3>
              <em><b>[NeurIPS 2023] (Oral)</b></em> <i>Thirty-seventh Conference on Neural Information Processing Systems</i> 
              <br>
              <a href="https://socalnlp.github.io/symp23/index.html">SoCal NLP 2023</a>, <a style="color:red"><b>Best Paper Award</b></a>
              <br>
              <a href="https://arxiv.org/pdf/2305.11554.pdf">PDF</a> / <a href="https://github.com/Ber666/ToolkenGPT">Code</a> / <a href="http://zhenwang9102.github.io/">Slides</a> / <a href="http://zhenwang9102.github.io/">Poster</a>
              <p>ToolkenGPT augments LLMs with massive tools/APIs by representing tools as tokens (“toolken”) and enabling tool calls in the same way as generating regular words. ToolkenGPT is super efficient for learning massive tools, as plugging in new tools is as easy as learning embeddings.</p>
            </td>
          </tr>
        </table>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="width:100%;vertical-align:middle;">
              <h3><a href="https://arxiv.org/abs/2303.02861">Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning</a></h3>
              <em><b>[ICLR 2023]</b></em> <i>The Eleventh International Conference on Learning Representations</i>
              <br>
              <a href="https://arxiv.org/pdf/2303.02861.pdf">PDF</a> / <a href="http://zhenwang9102.github.io/">Code</a> / <a href="http://zhenwang9102.github.io/">Slides</a> / <a href="http://zhenwang9102.github.io/">Poster</a> / <a href="https://github.com/huggingface/peft/pull/400">Huggingface PEFT PR</a>
              <p>We propose Multitask Prompt Tuning (MPT) to exploit the rich cross-task knowledge for more efficient and generalizable transfer learning. MPT learns a single transferrable soft prompt through the use of a novel combination of prompt decomposition and prompt distillation.</p>
            </td>          
          </tr>
          </table>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="width:100%;vertical-align:middle;">
              <h3><a href="https://arxiv.org/abs/2110.08294">Coherence Boosting: When Your Pretrained Language Model is <span style="color: #ff0000">Not</span> Paying Enough Attention</a></h3>
              <em><b>[ACL 2022]</b></em> <i>The 60th Annual Meeting of the Association for Computational Linguistics</i>
              <br>
              <a href="https://arxiv.org/pdf/2110.08294.pdf">PDF</a> / <a href="https://github.com/zhenwang9102/coherence-boosting">Code</a> / <a href="https://zhenwang9102.github.io/">Slides</a> / <a href="https://zhenwang9102.github.io/">Poster</a> <b>(Long Paper, Oral Presentation)</b>
              <p>We demonstrate that large language models have insufficiently learned the effect of distant words on next-token prediction. We present Coherence Boosting, an inference procedure that increases an LM’s focus on a long context, which greatly improves NLG and NLU tasks.</p>
            </td>          
          </tr>
          </table>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="width:100%;vertical-align:middle;">
              <h3><a href="https://arxiv.org/abs/2005.00889">Rationalizing Medical Relation Prediction from Corpus-level Statistics</a></h3>
              <em><b>[ACL 2020]</b></em> <i>The 58th Annual Meeting of the Association for Computational Linguistics</i>
              <br>
              <a href="https://zhenwang9102.github.io/files/ACL2020_ZW_X_MedRELA.pdf">PDF</a> / <a href="https://github.com/zhenwang9102/X-MedRELA">Code</a> / <a href="https://zhenwang9102.github.io/files/ACL2020-X-MedRELA-ZW-Slides.pdf">Slides</a> / <a href="https://zhenwang9102.github.io/">Poster</a> / <a href="https://slideslive.com/38929313/rationalizing-medical-relation-prediction-from-corpuslevel-statistics">Video</a> (Long Paper, Online Presentation)
              <p>We propose a self-interpretable framework to rationalize the neural relation prediction based on corpus-level statistics. This framework is inspired by human cognitive theory about recall and recognition, which provides structured knowledge triplets as rationales.</p>
            </td>
          </tr>
        
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="width:100%;vertical-align:middle;">
              <h3><a href="https://arxiv.org/abs/1906.09285">SurfCon: Synonym Discovery on Privacy-Aware Clinical Data</a></h3>
              <em><b>[KDD 2019]</b></em> <i>The 25th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</i>
              <br>
              <a href="https://zhenwang9102.github.io/files/KDD2019_ZW_SurfCon_paper.pdf">PDF</a> / <a href="https://github.com/zhenwang9102/SurfCon">Code</a> / <a href="https://zhenwang9102.github.io/files/KDD2019_ZW_SurfCon_Slides.pdf">Slides</a> / <a href="https://zhenwang9102.github.io/files/KDD2019_ZW_SurfCon_Poster.pdf">Poster</a> (Research Track, Long Paper, Oral Presentation)
              <p>We propose to discover structured knowledge--synonyms--from the privacy-aware text corpus and present a novel framework to leverage both surface form and context information to discover out-of-distribution synonyms.</p>
            </td>          
          </tr>
        </table>
        
            
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <p style="text-align:center;">
              <a href="https://clustrmaps.com/site/1beb5"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=3ckIy3WQFut4Emdkpn-xSRLuODAvOXCYLy3z-r53Gcs&cl=ffffff" /></a>
              </p>
              <br>
              <p style="text-align:center;font-size:small;">
                Source code from <a style="font-size:small;" href="https://leonidk.com/">Leonid Keselman</a>, design and inspiration from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron</a> and <a style="font-size:small;" href="https://dongkuanx27.github.io/">Dongkuan</a>.
              </p>
            </td>
          </tr>
        </table>
        
        
      </td>
    </tr>
  </table>
  
  
</body>
  

</html>
