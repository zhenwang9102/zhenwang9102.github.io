<!DOCTYPE HTML>
<html lang="en">

<head>
  <title>{{ site.name }}</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="{{ site.name }}" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="{{ site.baseurl }}/style.css" />
  <link rel="canonical" href="{{ page.url | replace:'index.html','' | prepend: site.baseurl | prepend: site.url }}">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
  
</head>

  
<style>
.listbox{
    position: static;
    overflow-y: scroll;
    height: 200px;
    color: black;
    background-color: #EAF4F7;
/*     border: 2px solid black; */
/*     padding: 20px 50px 0px 30px; */
/*     font-size: 15px; */
    }
</style>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <h1>
                Zhen Wang / çŽ‹éœ‡
              </h1>
              <p>
                Hi! I'm a computer science postdoctoral researcher working with Prof. <a href="http://www.cs.cmu.edu/~epxing/">Eric Xing</a> from <a href="https://www.cmu.edu/">CMU</a>/<a href="https://mbzuai.ac.ae/">MBZUAI</a> and Prof. <a href="http://zhiting.ucsd.edu/">Zhiting Hu</a> from <a href="https://ucsd.edu/">UCSD</a>. I received my PhD from <a href="https://www.osu.edu/">The Ohio State University</a>, advised by Prof. <a href="http://web.cse.ohio-state.edu/~sun.397/">Huan Sun</a>.
              </p>
              <p>
                In summer 2022, I interned at <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a> working with <a href="https://rpand002.github.io/">Rameswar</a>, <a href="https://people.csail.mit.edu/yoonkim/">Yoon</a>, <a href="https://scholar.google.com/citations?user=WbO7tjYAAAAJ&hl=en">Leonid</a>, and <a href="https://www.rogerioferis.org/">Rogerio</a> on efficient adaptation of large language models. In summer 2021, I was a research intern at the NLP group in <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-redmond/">Microsoft Research, Redmond</a>, working with <a href="https://www.microsoft.com/en-us/research/people/jojic/">Nebojsa</a> and <a href="https://malkin1729.github.io/">Kolya</a>, studying coherence boosting and prompting calibration on GPT-3. In summer 2020, I was a research intern at the Data Science team in <a href="https://www.nec-labs.com/">NEC Labs America</a> working with <a href="https://bzong.github.io/">Bo Zong</a>, exploring commonsense knowledge representation and reasoning.
              </p>
              <p style="text-align:center">
                <a href="mailto:zhenwang9102@gmail.com">Email</a> &nbsp;/&nbsp;
                <a href="https://zhenwang9102.github.io/files/ZW_CV.pdf">CV (Feb 2023)</a> &nbsp;/&nbsp;
                <a href="https://github.com/zhenwang9102">GitHub</a> &nbsp;/&nbsp;
                <a href="https://twitter.com/zhenwang9102">Twitter</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?hl=en&user=asBaytUAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a> 
<!--                 &nbsp;/&nbsp; -->
<!--                 <a href="https://www.linkedin.com/in/zhenwang9102/">LinkedIn </a>  -->
<!--                 &nbsp;/&nbsp; -->
<!--                 <a href="https://www.semanticscholar.org/author/Zhen-Wang/47197370">Semantic Scholar</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/IMG_0023_S.png">
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Research Overview</h2>
              <p>
                My research focuses on <b>human-centered AI</b> with the aim to infuse machine learning models, especially <a href="https://en.wikipedia.org/wiki/Foundation_models">foundation models</a>, with <b>a human-like understanding of world and knowledge to enable AI as both a reliable assistant and an insightful collaborator</b>. Future AI systems need to not only augement human capabilities but also resonate with human values, understandings, accessibility, and proactive problem-solving. My ultimate goal is not to build AI that merely replicate or replace human abilities, but to develop systems that enriches human experiences, amplify human potential, honour human values, and actively collaborate with us in addressing real-world challenges. 
              </p>
              <ol>
                <li>
                  <b>Interpreting and controlling ML models towards human values</b>: Transparency is key in human-centered AI. I develop methodologies to unlock the black box and ensure their behaivors align with human values, thus making them more controllable and transparent.
                  [<a style="text-decoration:underline;" href="https://arxiv.org/abs/2005.00889">ACL 2020</a>]
                  [<a style="text-decoration:underline;" href="https://arxiv.org/abs/2110.08294">ACL 2022</a>]
                  [<a style="text-decoration:underline;" href="https://arxiv.org/abs/2210.01293">ACL 2023</a>]
                  [<a style="text-decoration:underline;" href="https://arxiv.org/abs/2303.14310">New preprint</a>]
                </li>
                <li>
                  <b>Adapting and transferring knowledge for dynamic human needs</b>: 
                  Human-centered AI demands AI systems that can swiftly adapt and learn in response to the changing needs and circumstances of its human users. I develop efficient methods to transfer knowledge between AI systems and adapt them across diverse tasks and domains for greater accessibility.
                  [<a style="text-decoration:underline;" href="https://arxiv.org/abs/2303.02861">ICLR 2023</a>]
                  [<a style="text-decoration:underline;" href="https://aclanthology.org/2022.suki-1.7/">NAACL SUKI 2022</a>]
                  [<a style="text-decoration:underline;" href="https://arxiv.org/abs/2210.06444">EACL 2023</a>]
                </li>
                <li>
                  <b>Augmenting models to proactively solve real-world problems for humans</b>: 
                  An active problem-solving drive is a distinctive trait of human intelligence. I aim to elevate AI systems from passive respondents into proactive problem solvers by interacting with physical world and novel domains. 
                  [<a style="text-decoration:underline;" href="https://arxiv.org/abs/2305.11554">New preprint</a>]
                  [<a style="text-decoration:underline;" href="https://arxiv.org/abs/2305.14992">New preprint</a>]
                </li>
              </ol>
              <p>
                <b>Research Opportunities</b>: I consistently seek out highly motivated students, particularly from underrepresented groups, to join me in various research projects both during the school year and throughout the summer. If you are eager to enhance your research abilities and be a part of this exciting opportunity, kindly email me expressing your interest.
              </p>
            </td>
          </tr>
        </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>News</h2>
              <p></p>
              <div class="listbox">
                <ul>
                  <li>
                    05/2023: One paper about <a href="https://arxiv.org/abs/2210.01293" style="color:red">prompting LLMs with probabilistic reasoning</a> was accepted to <a href="https://2023.aclweb.org/">ACL 2023</a>!
                  </li>
                  <li>
                    03/2023: Invited to serve as a Reviewer for <a href="https://nips.cc/Conferences/2023">NeurIPS 2023</a>.
                  </li>
                  <li>
                    03/2023: Invited to serve as an Area Chair for <a href="http://tcci.ccf.org.cn/conference/2023/index.php">NLPCC 2023</a>.
                  </li>
                  <li>
                    02/2023: Kicked off my postdoc adventure! ðŸ˜Ž Super stoked to work with the brilliant minds from UCSD, CMU, MBZUAI, and beyond, to  push the boundaries of those incredible large language models and harness their power for the human society and other scientific domains! ðŸš€ðŸ”¬ðŸ’¡
                  </li>
                  <li>
                    01/2023: One paper, <a href="https://arxiv.org/abs/2303.02861" style="color:red">Multitask Prompt Tuning</a>, was accepted to <a href="https://iclr.cc/">ICLR 2023</a>!
                  </li>
                  <li>
                    01/2023: One paper, <a href="https://arxiv.org/abs/2210.06444" style="color:red">Entity Tracking via Effective Use of Multi-Task Learning Models</a>, was accepted to <a href="https://2023.eacl.org/">EACL 2023</a>!
                  </li>
                  <li>
                    01/2023: Invited to serve as a Reviewer for <a href="https://icml.cc/Conferences/2023">ICML 2023</a>.
                  </li>
                  <li>
                    12/2022: Invited to serve as a PC Member for <a href="https://kdd.org/kdd2023/">KDD 2023</a> Research Track.
                  </li>
                  <li>
                    12/2022: Happy to finish my first in-person NLP course teaching and I'm impressed by what students have achieved after learning the very advanced NLP techniques. Check out <a href="https://docs.google.com/presentation/d/1TA_Gf29CbGe0UV5NR_uPnaGr7dP7-ipNuz-BtNne3_0/edit?usp=sharing">this quick summary of their amazing final projects</a>!
                  </li>
                  <li>
                    11/2022: Passed the PhD dissertation defense, <a>Toward Knowledge-centric Natural Language Processing: Acquisition, Representation, Transfer, and Reasoning</a>. Thanks to all my committee members, Prof. Huan Sun, Srinivasan Parthasarathy, Yu Su and Wei-Lun Chao. 
                  </li>
                  <li>
                    08/2022: Will be teachinng <a>CSE 5525: Foundations of Speech and Language Processing (Undergrad & Graduate)</a> as an instructor at OSU this fall.
                  </li>
                  <li>
                    08/2022: Invited to serve as a PC member for <a href="https://aaai.org/Conferences/AAAI-23//">AAAI 2023</a>.
                  </li>
                  <li>
                    07/2022: Attended NAACL 2022 in Seattle. Presented <a href="https://aclanthology.org/2022.suki-1.7.pdf">our CQA Knowledge Transfer paper</a>. Glad to meet all old and new friends! 
                  </li>
                  <li>
                    06/2022: Invited to serve as a PC member for <a href="https://2022.emnlp.org/">EMNLP 2022</a>.
                  </li>
                  <li>
                    06/2022: Happy to give a talk about <a>Efficient Adaptation of Large Language Models</a> at the <a>MIT Summer Working Group on Large LMs</a>.
                  </li>
                  <li>
                    06/2022: Our TacoBot earned the <a href="https://www.amazon.science/alexa-prize/three-top-performers-emerge-in-inaugural-alexa-prize-taskbot-challenge" style="color:red">third-place honor in the inaugural Alexa Prize TaskBot Challenge</a>!
                  </li>
                  <li>
                    06/2022: Happy to give a tutorial about natural language processing and large language models in <a href="https://tdai.osu.edu/events/tdai-foundations-cop-deep-learning-summer-school">TDAI Deep Learning Summer School</a> along with Prof. Huan Sun. Slides can be found <a href="https://tdai.osu.edu/sites/default/files/2022-06/2022-foundations-tutorial3-sunwang-deeplearning4nlp.pdf">here</a>.
                  </li>
                  <li>
                    05/2022: Excited to join <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a> in Cambridge, Boston as a research intern working with <a href="https://rpand002.github.io/">Rameswar Panda</a> and <a href="https://people.csail.mit.edu/yoonkim/">Yoon Kim</a> on efficient adaptation/pruning for large language models.
                  </li>
                  <li>
                    03/2022: Our team TacoBot moved forward to finals of the <a href="https://www.amazon.science/alexa-prize/taskbot-challenge">Alexa Prize TaskBot challenge</a>!
                  </li>
                  <li>
                    03/2022: Honored to receive the <a>2022 Graduate Research Award</a> of the CSE department. 
                  </li>
                  <li>
                    02/2022: One paper, <a href="https://arxiv.org/abs/2110.08294">Coherence boosting: When your pretrained language model is not paying enough attention</a>, was accepted to <a href="https://www.2022.aclweb.org/">ACL 2022</a>!
                  </li>
                  <li>
                    02/2022: Our team TacoBot moved forward to semifinals of the <a href="https://www.amazon.science/alexa-prize/taskbot-challenge">Alexa Prize TaskBot challenge</a>! Try "<a href="https://www.amazon.science/blog/alexa-assist-me-is-now-live">Alexa, let's work together</a>" or "Alexa, assist me" in your Alexa devices or the app when you want to do a DIY or cooking task!
                  </li>
                  <li>
                    12/2021: Passed the PhD candidacy exam with the proposal, "<a href="https://zhenwang9102.github.io/files/candidacy_abstract.txt">Knowledge-centric Natural Language Processing: Acquisition, Representation, and Reasoning</a>". Thanks to all my committee members, Prof. Huan Sun, Srinivasan Parthasarathy, Yu Su and Wei-Lun Chao. 
                  </li>
                  <li>
                    05/2021: Our team was selected to participate in the <a href="https://www.amazon.science/alexa-prize/taskbot-challenge/2021">Alexa Prize TaskBot Challenge</a> as one of 10 teams over 125 applications initiated from 15 countries! Looking forward to building a smart dialogue system to guide users through complex, multi-step plans (e.g., Cooking and DIY tasks) via multimodal interactions.
                  </li>
                  <li>
                    05/2021: Started Research Intern at Microsoft Research! Excited to work with <a href="https://www.microsoft.com/en-us/research/people/jojic/">Nebojsa Jojic</a> and <a>Kolya Malkin</a> on Conditional Text Generation!
                  </li>
                  <li>
                    03/2021: Invited to serve as a PC member of EMNLP 2021.
                  </li>
                  <li>
                    03/2021: Attended WSDM 2021 virtually and present our work on <a href="https://dl.acm.org/doi/10.1145/3437963.3441744">modeling context pair interaction and learning graph pair emebddings</a>.
                  </li>
                  <li>
                    03/2021: Honored to win <a>Graduate Student Research Poster Award (Top 5)</a> for 2021 Annual Student Research Poster Exhibition in our CSE department.
                  </li>
                  <li>
                    02/2021: Panelist on the panel discussion in Department of Astronomy, "<a href="https://astronomy.osu.edu/events/monthly-movie-night-2001-space-odyssey-science-fiction-vs-science-fact">2001: A Space Odyssey - Science Fiction vs Science Fact</a>", discussing Artificial Intelligence, Life in Universe, Time & Relativity and Anthropology.
                  </li>
                  <li>
                    01/2021: Received SIGIR Student Travel Grant for WSDM 2021.
                  </li>
                  <li>
                    01/2021: Attended CDAC Rising Stars in Data Science Workshop with the agenda <a href="https://cdac.uchicago.edu/events/risingstars2021">here</a>.
                  </li>
                  <li>
                    12/2020: Honored to be selected to the <a href="https://datascience.uchicago.edu/rising-stars-alumni/" style="color:red">Rising Stars in Data Science</a> workshop hosted by the <a href="https://cdac.uchicago.edu/">Center for Data and Computing (CDAC) at the University of Chicago</a>.
                  </li>
                  <li> 
                    12/2020: Invited to serve as a PC member of ACL 2021.
                  </li>
                  <li> 
                    10/2020: Invited to serve as a PC member of NAACL 2021.
                  </li>
                  <li>
                    10/2020: One paper, <a href="https://zhenwang9102.github.io/files/WSDM2021_ZW_ConPI.pdf">Modeling Context Pair Interaction for Pairwise Tasks on Graphs</a>, was accepted to WSDM 2021 (<a style="color:red">Acceptance Rate: 18.6%</a>).
                  </li>
                  <li>
                    07/2020: Attended ACL 2020 virtually and presented our paper via QA sessions and pre-recorded video.
                  </li>
                  <li>
                    05/2020: Started Research Intern at <a href="http://www.nec-labs.com/">NEC Labs America</a>! Excited to work with <a href="https://bzong.github.io/">Dr. Bo Zong</a> on Commonsense Reasoning for NLU.
                  </li>
                  <li>
                    04/2020: One paper, <a href="https://zhenwang9102.github.io/files/ACL2020_ZW_X_MedRELA.pdf">Rationalizing Medical Relation Prediction from Corpus-level Statistics</a>, about building self-interpretable deep learning model for relation prediction was accepted by <a href="https://acl2020.org/"></a>ACL 2020 (<a style="color:red">Acceptance Rate: 22.7%</a>).
                  </li>
                  <li>
                    04/2020: Invited to serve as a PC member of NLPCC 2020.
                  </li>
                  <li>
                    09/2019: One paper, <a href="https://academic.oup.com/bioinformatics/article/36/4/1241/5581350">Graph Embedding on Biomedical Networks: Methods, Applications, and Evaluations</a>, was accepted by <a href="https://academic.oup.com/bioinformatics">Bioinformatics</a>.
                  </li>
                  <li>
                    08/2019: Attended KDD 2019 in Anchorage, Alaska and presented our work in an oral talk.
                  </li>
                  <li>
                    06/2019: Received SIGKDD Student Travel Award for KDD 2019.
                  </li>
                  <li>
                    04/2019: One paper, <a href="https://zhenwang9102.github.io/files/KDD2019_ZW_SurfCon_paper.pdf">SurfCon: Synonym Discovery on Privacy-Aware Clinical Data</a>, about knowledge extraction from text was accepted by <a href="https://www.kdd.org/kdd2019/">KDD 2019</a> (Research Track, <a style="color:red">Acceptance Rate: 14.2%</a>, Oral).
                  </li>
                  <li>
                    08/2018: One paper about <a href="https://ziyuyao.org/paper/StaQC_DLDay18.pdf">Code Summarization</a> was accepted by KDD 2018, Deep Learning Day.
                  </li>
                  <li>
                    06/2018: Attended NAACL 2018 in New Orleans, LA.
                  </li>
                </ul>
              </div>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Publications</h2>
            </td>
          </tr>
        </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Preprint</h2>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
          <td style="padding:20px;width:25%;vertical-align:middle;">
            <img src="/images/ArXiv_logo_2022.png" alt="ThinkSum" width="180" height="auto" style="border-style: none">
          </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://arxiv.org/abs/2305.14992">Reasoning with Language Model is Planning with World Model</a></h3>
              <br>
              Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, <b>Zhen Wang</b>, Daisy Zhe Wang, Zhiting Hu
              <br>
              <i><a href="https://arxiv.org/pdf/2305.14992.pdf">PDF</a></i>
              <br>
              <br>
              <h3><a href="https://arxiv.org/abs/2305.11554">ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings</a></h3>
              <br>
              Shibo Hao, Tianyang Liu, <b>Zhen Wang</b>, Zhiting Hu
              <br>
              <i><a href="https://arxiv.org/pdf/2305.11554.pdf">PDF</a></i>
              <br>
              <br>
              <h3><a href="https://arxiv.org/abs/2303.14310">GPT Is Becoming a Turing Machine: Here Are Some Ways to Program It</a></h3>
              <br>
              Ana Jojic, <b>Zhen Wang</b>, Nebojsa Jojic
              <br>
              <i><a href="https://arxiv.org/pdf/2303.14310.pdf">PDF</a></i>
            </td>
          </tr>
          </table>
 
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>2023</h2>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/thinksum_acl_2023.png" alt="thinksum_acl2023" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://arxiv.org/abs/2210.01293" style="color:red;">ThinkSum: Probabilistic Reasoning Over Sets Using Large Language Models</a></h3>
              <br>
              Batu Ozturkler, Nikolay Malkin, <b>Zhen Wang</b>, Nebojsa Jojic
              <br>
              <em><b>[ACL 2023]</b></em> <i>The 61st Annual Meeting of the Association for Computational Linguistics</i> (Main)
              <br>
              <a href="https://arxiv.org/pdf/2210.01293.pdf">PDF</a> / <a href="http://zhenwang9102.github.io/">Code</a> / <a href="http://zhenwang9102.github.io/">Slides</a> / <a href="http://zhenwang9102.github.io/">Poster</a>
              <p>We propose a two-stage probabilistic inference paradigm, ThinkSum, to improve LLMs' abilities of reasoning over multiple objects in two steps, Think (e.g., retrieval of associations) and Sum (e.g., aggregation of results), which beats chain-of-thought prompting in hard BIG-bench tasks.</p>
            </td>
          </tr>
        </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/mpt_overview.png" alt="mpt_iclr2023" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://arxiv.org/abs/2303.02861" style="color:red;">Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning</a></h3>
              <br>
              <b>Zhen Wang</b>, Rameswar Panda, Leonid Karlinsky, Rogerio Feris, Huan Sun, Yoon Kim
              <br>
              <em><b>[ICLR 2023]</b></em> <i>The Eleventh International Conference on Learning Representations</i>
              <br>
              <a href="https://arxiv.org/pdf/2303.02861.pdf">PDF</a> / <a href="http://zhenwang9102.github.io/">Code</a> / <a href="http://zhenwang9102.github.io/">Slides</a> / <a href="http://zhenwang9102.github.io/">Poster</a>
              <p>We propose Multitask Prompt Tuning (MPT) to exploit the rich cross-task knowledge for more efficient and generalizable transfer learning. MPT learns a single trasnferrable soft prompt through the use of a novel combination of prompt decomposition and prompt distillation.</p>
            </td>          
          </tr>
          </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/meet_eacl_2023.png" alt="meet_eacl2023" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://arxiv.org/abs/2210.06444" style="color:red;">Entity Tracking via Effective Use of Multi-Task Learning Models</a></h3>
              <br>
              Janvijay Singh, Fan Bai, <b>Zhen Wang</b>
              <br>
              <em><b>[EACL 2023]</b></em> <i>The 17th Conference of the European Chapter of the Association for Computational Linguistics</i> (Main)
              <br>
              <a href="https://arxiv.org/pdf/2210.06444.pdf">PDF</a> / <a href="https://github.com/iamjanvijay/MeeT">Code</a> / <a href="http://zhenwang9102.github.io/">Slides</a> / <a href="http://zhenwang9102.github.io/">Poster</a>
              <p>How to transfer multi-task knowledge from pre-training to niche downstream tasks, such as entity tracking on the procedural text? We show that you can reach STOA performance by simply fine-tuning T5 but with specialized QA prompt and task-specific decoding.</p>
            </td>
          </tr>
          </table>
            
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>2022</h2>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/dissertation_2022.png" alt="dissertation" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://www.proquest.com/openview/16bbeab89e764c0f8fcc14c65df7fe9b/1?pq-origsite=gscholar&cbl=18750&diss=y">Toward Knowledge-Centric NLP: Acquisition, Representation, Transfer, and Reasoning</a></h3>
              <br>
              <b>Zhen Wang</b>
              <br>
              <i>The Ohio State University, Ph.D. Dissertation, 2022</i>
              <br>
              <a href="https://zhenwang9102.github.io/files/Zhen_Dissertation_2022.pdf">PDF</a>
<!--               <p>We demonstrate that large language models have insufficiently learned the effect of distant words on next-token prediction. We present Coherence Boosting, an inference procedure that increases a LMâ€™s focus on a long context, which gets huge improvement on NLG and NLU tasks.</p> -->
            </td>          
          </tr>
        </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/cb_acl_2022.png" alt="cb_acl2022" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://arxiv.org/abs/2110.08294">Coherence Boosting: When Your Pretrained Language Model is <span style="color: #ff0000">Not</span> Paying Enough Attention</a></h3>
              <br>
              Nikolay Malkin, <b>Zhen Wang</b>, Nebojsa Jojic
              <br>
              <em><b>[ACL 2022]</b></em> <i>The 60th Annual Meeting of the Association for Computational Linguistics</i>
              <br>
              <a href="https://arxiv.org/pdf/2110.08294.pdf">PDF</a> / <a href="https://github.com/zhenwang9102/coherence-boosting">Code</a> / <a href="https://zhenwang9102.github.io/">Slides</a> / <a href="https://zhenwang9102.github.io/">Poster</a> <b>(Long Paper, Oral Presentation)</b>
              <p>We demonstrate that large language models have insufficiently learned the effect of distant words on next-token prediction. We present Coherence Boosting, an inference procedure that increases a LMâ€™s focus on a long context, which gets huge improvement on NLG and NLU tasks.</p>
            </td>          
          </tr>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/simultqa_2022.png" alt="SimultQA" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://aclanthology.org/2022.suki-1.7/">Knowledge Transfer between Structured and Unstructured Sources for Complex Question Answering</a></h3>
              <br>
              Lingbo Mo*, <b>Zhen Wang*</b>, Jie Zhao, Huan Sun
              <br>
              <em><a href="https://suki-workshop.github.io/"><b>[SUKI@NAACL 2022]</b></a></em> <i>NAACL 2022 Structured and Unstructured Knowledge Integration</i>
              <br>
              <a href="https://zhenwang9102.github.io/files/SimultQA_2022.pdf">PDF</a> / <a href="https://zhenwang9102.github.io/">Code</a> / <a href="https://zhenwang9102.github.io/">Slides</a> / <a href="https://zhenwang9102.github.io/">Poster</a> *Equal contribution
              <p>We study knowledge transfer for multi-hop reasoning processes between structured (Knowledge Base) and unstructred (text corpus) knowledge. We design SimultQA unifying KBQA and TextQA systems and leverage it to study how the reasoning is transferred between two knowledge sources.</p>
            </td>          
          </tr>
          </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>2021</h2>
            </td>
          </tr>
        </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/alexa_prize_figure.jpeg" alt="SimultQA" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://arxiv.org/abs/2207.05223">Bootstrapping a User-Centered Task-Oriented Dialogue System</a></h3>
              <br>
              Shijie Chen, Ziru Chen, Xiang Deng, Ashley Lewis, Lingbo Mo, Samuel Stevens, <b>Zhen Wang</b>, Xiang Yue, Tianshu Zhang, Yu Su, Huan Sun
              <br>
              <em><a href="https://www.amazon.science/alexa-prize/taskbot-challenge"><b>[Alexa Prize TaskBot Challenge]</b></a></em> <i>1st Proceedings of Alexa Prize TaskBot (Alexa Prize 2021)</i>
              <br>
              <a href="https://assets.amazon.science/9a/30/5e4931ec41d78abad730707ce95a/bootstrapping-a-user-centered-task-oriented-dialogue-system.pdf">PDF</a> / <a href="https://www.amazon.science/alexa-prize/three-top-performers-emerge-in-inaugural-alexa-prize-taskbot-challenge" style="color:red">Third-place honor in the TaskBot Finals!</a>
              <p>We build TacoBot, a task-oriented dialogue system for the inaugural Alexa Prize TaskBot Challenge to assist users in multi-step cooking and home improvement tasks. We propose several data augmentation methods, such as GPT-3 simulation to bootstrap neural dialogue systems into new domains and make them more robust to noise user initiatives.</p>
            </td>          
          </tr>
          </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/conpi_wsdm_2021.png" alt="conpi_wsdm_2021" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://zhenwang9102.github.io/files/WSDM2021_ZW_ConPI.pdf">Modeling Context Pair Interaction for Pairwise Tasks on Graphs</a></h3>
              <br>
              <b>Zhen Wang</b>, Bo Zong, Huan Sun
              <br>
              <em><b>[WSDM 2021]</b></em> <i>The 14th ACM International Conference on Web Search and Data Mining</i>
              <br>
              <a href="https://zhenwang9102.github.io/files/WSDM2021_ZW_ConPI.pdf">PDF</a> / <a href="https://github.com/zhenwang9102/ConPI">Code</a> / <a href="https://zhenwang9102.github.io/">Slides</a> / <a href="https://zhenwang9102.github.io/">Poster</a> (Long Paper, Online Presentation)
              <p>We propose to explicitly model context interactions for pairwise prediction tasks on graphs, which consists of two perspectives, node-centric and pair-centric. We also propose to pre-train pair embeddings to facilitate the pair-centric model.</p>
            </td>          
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>2020</h2>
            </td>
          </tr>
        </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/x-clinrela_acl__2020.png" alt="x-clinrela_acl__2020" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://arxiv.org/abs/2005.00889">Rationalizing Medical Relation Prediction from Corpus-level Statistics</a></h3>
              <br>
              <b>Zhen Wang</b>, Jennifer Lee, Simon Lin, Huan Sun
              <br>
              <em><b>[ACL 2020]</b></em> <i>The 58th Annual Meeting of the Association for Computational Linguistics</i>
              <br>
              <a href="https://zhenwang9102.github.io/files/ACL2020_ZW_X_MedRELA.pdf">PDF</a> / <a href="https://github.com/zhenwang9102/X-MedRELA">Code</a> / <a href="https://zhenwang9102.github.io/files/ACL2020-X-MedRELA-ZW-Slides.pdf">Slides</a> / <a href="https://zhenwang9102.github.io/">Poster</a> / <a href="https://slideslive.com/38929313/rationalizing-medical-relation-prediction-from-corpuslevel-statistics">Video</a> (Long Paper, Online Presentation)
              <p>We propose a self-interpretable framework to rationalize the neural relation prediction based on corpus-level statistics. This framework is inspired by human cognitive theory about recall and recognition, which provides structured knowledge triplets as rationales.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/graph_bioinformatics.png" alt="graph_bioinformatics" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://arxiv.org/abs/1906.05017">Graph Embedding on Biomedical Networks: Methods, Applications, and Evaluations</a></h3>
              <br>
              Xiang Yue, <b>Zhen Wang</b>, Jingong Huang, Srinivasan Parthasarathy, Soheil Moosavinasab, Yungui Huang, Simon Lin, Wen Zhang, Ping Zhang, Huan Sun
              <br>
              <em><b>[Bioinformatics]</b></em> <i>Volume 36, Issue 4, 15 February 2020, Pages 1241-1251</i>
              <br>
              <a href="https://academic.oup.com/bioinformatics/article/36/4/1241/5581350">PDF</a> / <a href="https://github.com/xiangyue9607/BioNEV">Code</a> / <a href="https://zhenwang9102.github.io/">Slides</a> / <a href="https://zhenwang9102.github.io/">Poster</a>
              <p>We benchmark 11 representative graph embedding methods on 5 important biomedical tasks. We verify the effectivenes of recent graph embedding methods and provide general guidelines for their usage.</p>
            </td>          
          </tr>
        </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>2019</h2>
            </td>
          </tr>
        </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/surfcon_kdd_2019.png" alt="surfcon_kdd_2019" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://arxiv.org/abs/1906.09285">SurfCon: Synonym Discovery on Privacy-Aware Clinical Data</a></h3>
              <br>
              <b>Zhen Wang</b>, Xiang Yue, Soheil Moosavinasab, Yungui Huang, Simon Lin, Huan Sun
              <br>
              <em><b>[KDD 2019]</b></em> <i>The 25th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</i>
              <br>
              <a href="https://zhenwang9102.github.io/files/KDD2019_ZW_SurfCon_paper.pdf">PDF</a> / <a href="https://github.com/zhenwang9102/SurfCon">Code</a> / <a href="https://zhenwang9102.github.io/files/KDD2019_ZW_SurfCon_Slides.pdf">Slides</a> / <a href="https://zhenwang9102.github.io/files/KDD2019_ZW_SurfCon_Poster.pdf">Poster</a> (Research Track, Long Paper, Oral Presentation)
              <p>We propose to discover structured knowledge, synonyms from privacy-aware text corpus and present a novel framework to leverage both surface form and context information to discover out-of-distribution synonyms.</p>
            </td>          
          </tr>
        </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Before 2019</h2>
            </td>
          </tr>
        </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/code_kdd_2018_dlday.png" alt="code_kdd_2018_dlday" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://ziyuyao.org/paper/StaQC_DLDay18.pdf">A Comprehensive Study of StaQC for Deep Code Summarization</a></h3>
              <br>
               Jayavardhan Reddy Peddamail, Ziyu Yao, <b>Zhen Wang</b>, Huan Sun
              <br>
              <em><b>[KDD 2018 Deep Learning Day]</b></em> <i>The 24th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</i>
              <br>
              <a href="https://ziyuyao.org/paper/StaQC_DLDay18.pdf">PDF</a> / <a href="https://zhenwang9102.github.io/">Code</a> / <a href="https://zhenwang9102.github.io/">Slides</a> / <a href="https://zhenwang9102.github.io/">Poster</a> (SPOTLIGHT)
              <p>We examine three popular datasets mined from Stack Overflow on the code summarization task and show that StaQC (Stack Overflow Question-Code pairs) helps achieve substantially better results.</p>
            </td>          
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/hessian_mmm_2015.png" alt="hessian_mmm_2015" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://zhenwang9102.github.io/files/MMM2015_HessianSC.pdf">Hessian Regularized Sparse Coding for Human Action Recognition</a></h3>
              <br>
              Weifeng Liu, <b>Zhen Wang</b>, Dapeng Tao, Jun Yu
              <br>
              <em><b>[MMM 2015]</b></em> <i>The 21th International Conference on Multimedia Modeling</i>
              <br>
              <a href="https://zhenwang9102.github.io/files/MMM2015_HessianSC.pdf">PDF</a> / <a href="https://zhenwang9102.github.io/">Code</a> / <a href="https://zhenwang9102.github.io/">Slides</a> / <a href="https://zhenwang9102.github.io/">Poster</a> /
              <a onclick="if (document.getElementById(&quot;UAC-GANs&quot;).style.display==&quot;none&quot;) document.getElementById(&quot;UAC-GANs&quot;).style.display=&quot;block&quot;; else document.getElementById(&quot;UAC-GANs&quot;).style.display=&quot;none&quot;;">Bibtex</a>
              <div class="BibtexExpand" id="UAC-GANs" style="display: none;">
                  <pre>@inproceedings{liu2015hessian,
                  title={Hessian regularized sparse coding for human action recognition},
                  author={Liu, Weifeng and Wang, Zhen and Tao, Dapeng and Yu, Jun},
                  booktitle={International Conference on Multimedia Modeling},
                  pages={502--511},
                  year={2015},
                  organization={Springer}
                  }
                  </pre>
              </div>
              <p>We propose Hessian regularized sparse coding (HessianSC) for action recognition, which can well preserve the local geometry and steer the sparse coding varying linearly along the manifold of data distribution.</p>
            </td>          
          </tr>
        </table>
        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Honors and Awards</h2>
              <ul>
                <li>
                  Third-Place Honor, Inaugural Alexa Prize TaskBot Challenge, 2022
                </li>
                <li>
                  Graduate Research Award, CSE, OSU, 2022
                </li>
                <li>
                  Graduate Student Research Poster Award (Top 5), CSE, OSU, 2021
                </li>
                <li>
                  SIGIR Student Travel Grant, 2021
                </li>
                <li>
                  <a href="https://datascience.uchicago.edu/research/postdoctoral-programs/rising-stars/2021/" style="color:red"><b>Rising Stars in Data Science</b></a>, Center for Data and Computing (CDAC), University of Chicago, January 2021
                </li>
                <li>
                  SIGKDD Student Travel Award, 2019
                </li>
                <li>
                  <b>China Scholarship Council (CSC) Scholarship</b> (fully funded visiting program in <a href="https://www.polytech-reseau.org/en/polytech-nice-sophia/">Polytech Nice Sophia</a>), Nice, France, 2015
                </li>
                <li>
                  <b>National Scholarship</b>, China, 2014
                </li>
                <li>
                  Soong Ching Ling Foundation (SCLF) Scholarship, China, 2013                  
                </li>
                <li>
                  National Scholarship for Encouragement, China, 2012
                </li>
              </ul>
            </td>
          </tr>
        </table>
        
         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Services</h2>
              <ul>
                <b>Area Chair or Senior PC Member:</b>
                <ul>
                  <li>
                    NLPCC 2023
                  </li>
                </ul>
                <b>Program Committee Member:</b>
                <ul>
                  <li>
                    ACL ARR (Oct'21, Nov'21, Jan'22, Apr'22, Sep'22, Oct'22, Dec'22, Feb'23)
                  </li>
                  <li>
                    NAACL (2021, 2022 <b><a href="https://suki-workshop.github.io/">SUKI 2022</a></b> Workshop)
                  </li>
                  <li>
                    EMNLP (2021, 2022)
                  </li>
                  <li>
                    ACL (2021, 2023)
                  </li>
                  <li>
                    ICML 2023
                  </li>
                  <li>
                    NeurIPS 2023
                  </li>
                  <li>
                    KDD 2023
                  </li>
                  <li>
                    AAAI 2023
                  </li>
                  <li>
                    NLPCC (2020, 2021, 2022)
                  </li>
                </ul>
                <b>External Reviewer:</b>
                <ul>
                  <li>
                    KDD (2019, 2020), ACL 2018, ICDM 2018
                  </li>
                </ul>
              </ul>
            </td>
          </tr>
        </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <p style="text-align:center;">
              <a href="https://clustrmaps.com/site/1beb5"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=3ckIy3WQFut4Emdkpn-xSRLuODAvOXCYLy3z-r53Gcs&cl=ffffff" /></a>
              </p>
              <br>
              <p style="text-align:center;font-size:small;">
                Source code from <a href="https://leonidk.com/">Leonid Keselman</a>, design and inspiration from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron</a> and <a href="http://personal.psu.edu/dux19/">Dongkuan</a>.
              </p>
            </td>
          </tr>
        </table>
        
        
      </td>
    </tr>
  </table>
  
  
</body>
  

</html>
