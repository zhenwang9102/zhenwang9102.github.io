<!DOCTYPE HTML>
<html lang="en">

<head>
  <title>Zhen Wang</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="{{ site.name }}" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="/style.css">
<!--   <link rel="canonical" href="{{ page.url | replace:'index.html','' | prepend: site.baseurl | prepend: site.url }}"> -->
<!--   <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css"> -->
  
</head>

  
<style>
.listbox{
    position: static;
    overflow-y: scroll;
    height: 200px;
    color: black;
    background-color: #EAF4F7;
/*     border: 2px solid black; */
/*     padding: 20px 50px 0px 30px; */
/*     font-size: 15px; */
    }
</style>

  
<style>
  .navA{
    display: inline-block;
    margin-right: 13px;
    font-size: 16px;
    font-weight: 700;
    color: #000;
    text-decoration: none;
    padding: 5px ;
    border: #000 1px solid;
  }
  .navA:hover{
    color: #fff;
    background-color: #000;
  }
</style>
  

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        

        <div class="navbar" style="padding-left: 18px;">
          <a href="/index.html" class="navA">About</a>
          <a href="/page_research.html" class="navA">Research Overview</a>
          <a href="/page_pubs.html" class="navA">Publications</a>
          <a href="/page_posts.html" class="navA">Blogs</a>
          <a href="/page_honors_and_services.html" class="navA">Honors and Services</a>
        </div>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Blogs</h2>
              <br>
              <p>I write blogs from time to time to introduce some of my new research topics or reflect on past research. (Opinions expressed are my own.)</p>
            </td>
          </tr>
        </table>

      <hr width="100%" size="2">

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/blog_agi_race.png" alt="agi-race" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://medium.com/@wangzhen_60071/why-the-current-agi-race-may-fail-us-all-2b1aaf163426" style="color:red">Will the current AGI race fail us all?</a></h3>
              <br>
              Sept, 2025
              <br>
              <p>
                Drawing from an analogy in Liu Cixin’s The Three-Body Problem, I challenge the current AI race as a dangerous commitment to a single, brute-force path of "scaling." I view this approach as a symptom of our scientific ignorance; unable to achieve elegant humanlike generalizability, we resort to feeding the machine everything. In addition to not overglorifying this brute-force path, I advocate that alternatives should be allowed,  funded, and explored with the same vigor, such as task-specific scientific discovery.
              </p>
            </td>
          </tr>
        </table>
        
      <hr width="100%" size="2">

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/blog_chatgpt_year_2.png" alt="chatgpt-year-2" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://www.notion.so/zhenwang/ChatGPT-s-Second-Year-10-Aha-Moments-of-2024-That-Rewired-2025-15a0404f81f58028adf6ed4d402187f5" style="color:red">ChatGPT's Second Year: 10 Aha Moments of 2024 That Rewired 2025</a></h3>
              <br>
              Jan, 2025
              <br>
              <p>Here comes the second consecutive blog along the ChatGPT/AI "twist" Reflection Series. The scaling of computing in 2024 is slowing down, while inference-time scaling emerged. Again, 2024 delivered a series of unexpected “plot twists,” ranging from rethinking how LLMs handle reasoning and benchmarks and LLM agents to the seamless integration of multimodal I/O, small language models, persona vs. personalization, world models, AI scientists, etc. We shall see more vibrant "twists" in 2025. </p>
            </td>
          </tr>
        </table>
        
        <hr width="100%" size="2">

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/blog_de_arena.png" alt="decentralized_arena" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://de-arena.maitrix.org/">Decentralized Arena via Collective LLM Intelligence</a></h3>
              <br>
              Building Automated, Robust, and Transparent LLM Evaluation for Numerous Dimensions
              <br>
              Oct, 2024
              <br>
              <p>This blog introduces Decentralized Arena (DeArena), <b>the first scalable, automated LLM evaluation system</b>, expanding and refining the "Chatbot Arena" concept across a wide range of dimensions. By enabling LLMs to evaluate each other, DeArena fosters <b>a transparent, autonomous, and reproducible approach</b> to AI benchmarking, minimizing bias and computational demands through an efficient sorting-based algorithm that outperforms traditional methods. Its potential reaches into the oversight of future superintelligence, offering a democratic, collective intelligence-driven alternative when human judgment becomes insufficient or unreliable.</p>
            </td>
          </tr>
        </table>

        <hr width="100%" size="2">
        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/blog_txt360_from_llm360.png" alt="txt360_from_llm360" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://huggingface.co/spaces/LLM360/TxT360">TxT360: A Top-Quality LLM Pre-training Dataset Requires the Perfect Blend
</a></h3>
              <br>
              Oct, 2024
              <br>
              <p>This blog introduces TxT360 (Trillion eXtracted Text), a large-scale pre-training dataset from LLM360. It is <b>the first dataset to globally deduplicate 99 CommonCrawl snapshots and 14 high-quality data sources</b> from diverse domains (e.g., FreeLaw, PG-19, etc.). We released this blog to explain every detail of how TxT360 was produced. Participating in this great project and leading several initiatives gave me better insights into <b>how data scaling works in balancing noisy web and highly curated data</b>.</p>
            </td>
          </tr>
        </table>


        <hr width="100%" size="2">
  
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <img src="/images/blog_chatgpt_year_1.png" alt="chatgpt-year-1" width="180" height="auto" style="border-style: none">
            </td>
            <td style="width:75%;vertical-align:middle;">
              <h3><a href="https://zhenwang.notion.site/Reflecting-on-ChatGPT-s-First-Year-Evolutions-Twists-and-Smooth-Directions-2381d752b5c94012bd21269f46d12a08">Reflecting on ChatGPT’s First Year: Evolutions, Twists, and Smooth Directions</a></h3>
              <br>
              Jan, 2024
              <br>
              <p>About one year after ChatGPT's release, this blog reflects on its impact on LLM research, examining which new topics have emerged and which older ones have become less relevant. What surprised me most is <b>how rapidly the field has evolved in just one year</b>. I highlighted several <b>"twisted" directions</b>, meaning areas where there has been an unexpected surge or decline in academic interest. In contrast, some <b>"smooth" directions</b> have consistently received significant research attention. By better understanding these shifts in research focus, we can more accurately measure the influence of ChatGPT-related techniques and more effectively prioritize the impactful areas we want to explore next. </p>
<!--               <p>Stay tuned for the blog, <b>Reflecting on ChatGPT's Second Year</b> at the end of 2024!</p> -->
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <p style="text-align:center;">
                <a href="https://clustrmaps.com/site/1c85c"  title="ClustrMaps"><img src="//www.clustrmaps.com/map_v2.png?d=Z_LvieCN3EbSxzA7WZG5Chqk2tagYjQYT-ZVbwMi1zg&cl=ffffff" /></a>
              </p>
            </td>
          </tr>
        </table>


      </td>
    </tr>
  </table>
  
  
</body>
  

</html>
